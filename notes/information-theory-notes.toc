\contentsline {section}{\numberline {1}The Source Coding Theorem}{1}% 
\contentsline {subsection}{\numberline {1.1}A basic example}{1}% 
\contentsline {section}{\numberline {2}Maximum Entropy Principle}{5}% 
\contentsline {section}{\numberline {3}Core ideas in information theory}{5}% 
\contentsline {section}{\numberline {4}Dyadic $U$ and symbol counting}{7}% 
\contentsline {section}{\numberline {5}Optimality of Huffman Codes}{8}% 
\contentsline {section}{\numberline {6}Channel Capacity}{9}% 
\contentsline {subsubsection}{\numberline {6.0.1}Examples}{10}% 
\contentsline {subsection}{\numberline {6.1}Information of Continuous Random Variables}{11}% 
\contentsline {subsection}{\numberline {6.2}Exercises}{12}% 
\contentsline {subsection}{\numberline {6.3}Examples}{14}% 
\contentsline {section}{\numberline {7}Constraints and communication theory}{16}% 
\contentsline {subsection}{\numberline {7.1}Joint Asymptotic Equipartition Principle}{19}% 
\contentsline {section}{\numberline {8}Channel Capacity Theorem}{20}% 
\contentsline {subsection}{\numberline {8.1}Joint AEP}{22}% 
\contentsline {subsection}{\numberline {8.2}Relation of AEP to Communication Problem}{23}% 
\contentsline {section}{\numberline {9}Channel Coding Theorem; Converse Part}{25}% 
\contentsline {section}{\numberline {10}Lossy Compression \& Rate Distortion Theory}{28}% 
\contentsline {subsection}{\numberline {10.1}Lossy compression problem setting}{28}% 
\contentsline {subsection}{\numberline {10.2}Qualitative analysis of $R(D)$}{29}% 
\contentsline {subsection}{\numberline {10.3}Examples}{31}% 
\contentsline {section}{\numberline {11}Method of Types}{32}% 
\contentsline {section}{\numberline {12}Strong, Conditional, and Joint Typicality}{33}% 
